{"meta":{"title":"Barry's blog","subtitle":"Run!!!","description":"run barry, run!","author":"Barry Wang","url":"http://yoursite.com","root":"/"},"pages":[{"title":"about","date":"2019-07-12T08:27:37.000Z","updated":"2019-07-12T08:27:37.233Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"����","date":"2019-07-12T08:22:33.000Z","updated":"2019-07-12T08:23:15.497Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"��ǩ","date":"2019-07-12T08:26:06.000Z","updated":"2019-07-12T08:26:34.086Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"Chapter2","date":"2019-08-05T03:55:52.844Z","updated":"2019-08-05T03:59:00.767Z","comments":true,"path":"2019/08/05/Chapter2/","link":"","permalink":"http://yoursite.com/2019/08/05/Chapter2/","excerpt":"","text":"title: Chapter 2categories: feature projecttags: 特征工程入门与实践 特征理解123456import pandas as pdimport numpy as npimport matplotlib.pyplot as plt import seaborn as sns %matplotlib inline plt.style.use('fivethirtyeight') 1salary_ranges = pd.read_csv('Salary_Ranges_by_Job_Classification.csv') 1salary_ranges.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } SetID Job Code Eff Date Sal End Date Salary SetID Sal Plan Grade Step Biweekly High Rate Biweekly Low Rate Union Code Extended Step Pay Type 0 COMMN 0109 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 $0.00 $0.00 330 0 C 1 COMMN 0110 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 $15.00 $15.00 323 0 D 2 COMMN 0111 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 $25.00 $25.00 323 0 D 3 COMMN 0112 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 $50.00 $50.00 323 0 D 4 COMMN 0114 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 $100.00 $100.00 323 0 M 1salary_ranges.columns Index([&apos;SetID&apos;, &apos;Job Code&apos;, &apos;Eff Date&apos;, &apos;Sal End Date&apos;, &apos;Salary SetID&apos;, &apos;Sal Plan&apos;, &apos;Grade&apos;, &apos;Step&apos;, &apos;Biweekly High Rate&apos;, &apos;Biweekly Low Rate&apos;, &apos;Union Code&apos;, &apos;Extended Step&apos;, &apos;Pay Type&apos;], dtype=&apos;object&apos;)1salary_ranges.info() &lt;class &apos;pandas.core.frame.DataFrame&apos;&gt; RangeIndex: 1356 entries, 0 to 1355 Data columns (total 13 columns): SetID 1356 non-null object Job Code 1356 non-null object Eff Date 1356 non-null object Sal End Date 1356 non-null object Salary SetID 1356 non-null object Sal Plan 1356 non-null object Grade 1356 non-null object Step 1356 non-null int64 Biweekly High Rate 1356 non-null object Biweekly Low Rate 1356 non-null object Union Code 1356 non-null int64 Extended Step 1356 non-null int64 Pay Type 1356 non-null object dtypes: int64(3), object(10) memory usage: 137.8+ KB1salary_ranges.isnull().sum() SetID 0 Job Code 0 Eff Date 0 Sal End Date 0 Salary SetID 0 Sal Plan 0 Grade 0 Step 0 Biweekly High Rate 0 Biweekly Low Rate 0 Union Code 0 Extended Step 0 Pay Type 0 dtype: int641salary_ranges.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Step Union Code Extended Step count 1356.000000 1356.000000 1356.000000 mean 1.294985 392.676991 0.150442 std 1.045816 338.100562 1.006734 min 1.000000 1.000000 0.000000 25% 1.000000 21.000000 0.000000 50% 1.000000 351.000000 0.000000 75% 1.000000 790.000000 0.000000 max 5.000000 990.000000 11.000000 1salary_ranges[['Biweekly High Rate','Grade']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Biweekly High Rate Grade 0 $0.00 00000 1 $15.00 00000 2 $25.00 00000 3 $50.00 00000 4 $100.00 00000 5 $100.00 00000 6 $200.00 00000 7 $500.00 00000 8 $0.00 00000 9 $10630.00 0140F 10 $9175.00 0150F 11 $4142.00 0170F 12 $5242.00 0180F 13 $3293.00 0190F 14 $4496.00 0380F 15 $4676.00 0381F 16 $4762.00 0382F 17 $11255.00 0390F 18 $10376.00 0395F 19 $9096.00 0400F 20 $9456.00 0401F 21 $9641.00 0402F 22 $7392.00 0488F 23 $7687.00 0489F 24 $7835.00 0490F 25 $3794.62 0720F 26 $1326.00 05475 27 $1425.00 05625 28 $1532.00 05775 29 $1646.00 05925 ... ... ... 1326 $4857.00 Q37H0 1327 $4586.00 Q50H0 1328 $4770.00 Q51H0 1329 $4857.00 Q52H0 1330 $5237.00 Q60H0 1331 $5445.00 Q61H0 1332 $5548.00 Q62H0 1333 $6616.00 Q80H0 1334 $6881.00 Q81H0 1335 $7011.00 Q82H0 1336 $6515.00 Q90H0 1337 $2178.00 06500 1338 $2342.00 06650 1339 $2700.00 06940 1340 $2354.00 06660 1341 $3234.00 07310 1342 $1909.00 06230 1343 $2332.00 06640 1344 $2459.00 06750 1345 $2354.00 06660 1346 $3199.00 07290 1347 $3426.00 07430 1348 $3689.00 07580 1349 $1951.00 06275 1350 $2786.00 07005 1351 $2145.00 06470 1352 $3041.00 07185 1353 $3132.00 07245 1354 $3453.00 07445 1355 $3453.00 07445 1356 rows × 2 columns 1salary_ranges['Biweekly High Rate'] = salary_ranges['Biweekly High Rate'].map(lambda x : x.replace('$','')) 1salary_ranges['Biweekly High Rate'] 0 0.00 1 15.00 2 25.00 3 50.00 4 100.00 5 100.00 6 200.00 7 500.00 8 0.00 9 10630.00 10 9175.00 11 4142.00 12 5242.00 13 3293.00 14 4496.00 15 4676.00 16 4762.00 17 11255.00 18 10376.00 19 9096.00 20 9456.00 21 9641.00 22 7392.00 23 7687.00 24 7835.00 25 3794.62 26 1326.00 27 1425.00 28 1532.00 29 1646.00 ... 1326 4857.00 1327 4586.00 1328 4770.00 1329 4857.00 1330 5237.00 1331 5445.00 1332 5548.00 1333 6616.00 1334 6881.00 1335 7011.00 1336 6515.00 1337 2178.00 1338 2342.00 1339 2700.00 1340 2354.00 1341 3234.00 1342 1909.00 1343 2332.00 1344 2459.00 1345 2354.00 1346 3199.00 1347 3426.00 1348 3689.00 1349 1951.00 1350 2786.00 1351 2145.00 1352 3041.00 1353 3132.00 1354 3453.00 1355 3453.00 Name: Biweekly High Rate, Length: 1356, dtype: object1salary_ranges['Biweekly High Rate'] = salary_ranges['Biweekly High Rate'].astype(float) 1salary_ranges['Grade'] = salary_ranges['Grade'].astype(str) 1salary_ranges.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } SetID Job Code Eff Date Sal End Date Salary SetID Sal Plan Grade Step Biweekly High Rate Biweekly Low Rate Union Code Extended Step Pay Type 0 COMMN 0109 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 0.0 $0.00 330 0 C 1 COMMN 0110 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 15.0 $15.00 323 0 D 2 COMMN 0111 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 25.0 $25.00 323 0 D 3 COMMN 0112 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 50.0 $50.00 323 0 D 4 COMMN 0114 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 100.0 $100.00 323 0 M 定类等级1salary_ranges['Grade'].value_counts().head() 00000 61 07450 12 06870 9 07420 9 07170 9 Name: Grade, dtype: int64 柱状图 1salary_ranges['Grade'].value_counts().sort_values(ascending = False).head(20).plot(kind = 'bar'); 1salary_ranges['Grade'].value_counts().sort_values(ascending = False).head(5).plot(kind = 'pie'); 定序等级1!cd E:\\Python\\特征工程入门与实践1customer = pd.read_csv('data/2013_SFO_Customer_survey.csv') 1customer.shape (3535, 95)12art_ratings = customer['Q7A_ART']art_ratings.describe() count 3535.000000 mean 4.300707 std 1.341445 min 0.000000 25% 3.000000 50% 4.000000 75% 5.000000 max 6.000000 Name: Q7A_ART, dtype: float641art_ratings = art_ratings[(art_ratings &gt; 1) &amp; (art_ratings &lt;= 5)] 12art_ratings = art_ratings.astype(str)art_ratings.describe() count 2636 unique 4 top 4 freq 1066 Name: Q7A_ART, dtype: object1art_ratings.value_counts().plot(kind = 'pie'); 1art_ratings.value_counts().plot(kind = 'bar'); 1art_ratings.value_counts().plot(kind = 'box'); 定序等级1climate = pd.read_csv('data/GlobalLandTemperaturesByCity.csv') 1climate.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dt AverageTemperature AverageTemperatureUncertainty City Country Latitude Longitude 0 1743-11-01 6.068 1.737 Århus Denmark 57.05N 10.33E 1 1743-12-01 NaN NaN Århus Denmark 57.05N 10.33E 2 1744-01-01 NaN NaN Århus Denmark 57.05N 10.33E 3 1744-02-01 NaN NaN Århus Denmark 57.05N 10.33E 4 1744-03-01 NaN NaN Århus Denmark 57.05N 10.33E 12# 移除缺失值climate.dropna(axis = 0, inplace = True) 1climate.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dt AverageTemperature AverageTemperatureUncertainty City Country Latitude Longitude 0 1743-11-01 6.068 1.737 Århus Denmark 57.05N 10.33E 5 1744-04-01 5.788 3.624 Århus Denmark 57.05N 10.33E 6 1744-05-01 10.644 1.283 Århus Denmark 57.05N 10.33E 7 1744-06-01 14.051 1.347 Århus Denmark 57.05N 10.33E 8 1744-07-01 16.082 1.396 Århus Denmark 57.05N 10.33E 1climate.isnull().sum() dt 0 AverageTemperature 0 AverageTemperatureUncertainty 0 City 0 Country 0 Latitude 0 Longitude 0 dtype: int641climate['AverageTemperature'].hist(); 1climate['AverageTemperature'].mean() 16.727432636247972123climate['dt'] = pd.to_datetime(climate['dt'])climate['year'] = climate['dt'].map(lambda x: x.year)climate_sub_us = climate.loc[climate['Country'] == 'United States'] 1climate_sub_us['century'] = climate_sub_us['year'].map(lambda x : int(x/100 + 1)) D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy &quot;&quot;&quot;Entry point for launching an IPython kernel.1climate_sub_us.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dt AverageTemperature AverageTemperatureUncertainty City Country Latitude Longitude year century 47555 1820-01-01 2.101 3.217 Abilene United States 32.95N 100.53W 1820 19 47556 1820-02-01 6.926 2.853 Abilene United States 32.95N 100.53W 1820 19 47557 1820-03-01 10.767 2.395 Abilene United States 32.95N 100.53W 1820 19 47558 1820-04-01 17.989 2.202 Abilene United States 32.95N 100.53W 1820 19 47559 1820-05-01 21.809 2.036 Abilene United States 32.95N 100.53W 1820 19 1climate_sub_us['AverageTemperature'].hist(by = climate_sub_us[\"century\"], sharex = True, sharey = True, figsize = (10,10), bins = 20); 1climate_sub_us.groupby('century')['AverageTemperature'].mean().plot(kind = 'line'); 12century_changes = climate_sub_us.groupby('century')['AverageTemperature'].mean()century_changes century 18 12.073243 19 13.662870 20 14.386622 21 15.197692 Name: AverageTemperature, dtype: float641century_changes[21] - century_changes[18] 3.12444911546075412345x = climate_sub_us['year']y = climate_sub_us['AverageTemperature']fig, ax = plt.subplots(figsize = (10,5))ax.scatter(x,y)plt.show() 1climate_sub_us.groupby('year').mean()['AverageTemperature'].plot(); 使用滑动均值平滑曲线 1climate_sub_us.groupby('year').mean()['AverageTemperature'].rolling(10).mean().plot(); 定比等级123456fig = plt.figure(figsize = (15,5))ax = fig.gca()salary_ranges.groupby('Grade')[['Biweekly High Rate']].mean().sort_values('Biweekly High Rate',ascending = False).head(20).plot.bar( stacked = False, ax= ax, color = 'darkorange');ax.set_title('Top 20 Grade by mean Biweekly High Rate'); 比较工资最高的员工与工资最低员工的差距 1sorted_df = salary_ranges.groupby('Grade')[['Biweekly High Rate']].mean().sort_values('Biweekly High Rate',ascending = False) 1sorted_df.iloc[0][0] / sorted_df.iloc[-1][0] 13.931919540229886","categories":[],"tags":[]},{"title":"","slug":"Google Colab使用 一","date":"2019-07-12T12:38:03.856Z","updated":"2019-07-12T12:38:04.567Z","comments":true,"path":"2019/07/12/Google Colab使用 一/","link":"","permalink":"http://yoursite.com/2019/07/12/Google Colab使用 一/","excerpt":"","text":"本地运行借助 Colaboratory，使用 Jupyter 连接到本地运行时 本机安装Jupyter 安装并启用jupyter_http_over_ws jupyter 扩展程序 12pip install jupyter_http_over_wsjupyter serverextension enable --py jupyter_http_over_ws 启动服务器并进行身份验证 1234jupyter notebook \\ --NotebookApp.allow_origin=&apos;https://colab.research.google.com&apos; \\ --port=8888 \\ --NotebookApp.port_retries=0 在 Colaboratory 中，点击“连接”按钮，然后选择“连接到本地运行时…”。在随即显示的对话框中输入上一步中的端口，然后点击“连接”按钮。完成此操作后，您应该就已经连接到本地运行时了。 Google Colab 123from google.colab import files files.upload()files.download()","categories":[],"tags":[]},{"title":"Tips(2)","slug":"Tips (2)","date":"2019-07-12T12:37:55.075Z","updated":"2019-07-28T06:43:24.672Z","comments":true,"path":"2019/07/12/Tips (2)/","link":"","permalink":"http://yoursite.com/2019/07/12/Tips (2)/","excerpt":"","text":"Ubuntu 18.01 重装mysql 删除mysql 123 #sudo apt autoremove mysql-server #sudo apt remove mysql-common#dpkg -l |grep ^rc|awk &apos;&#123;print $2&#125;&apos; |sudo xargs dpkg -P 安装 mysql 123#sudo apt install mysql-server#sudo apt install mysql-client#sudo apt install php5-mysql php和mysql连接 若提示Package has no installation candidate 123sudo apt-get update sudo apt install upgradesudo apt install php5-mysql","categories":[],"tags":[]},{"title":"","slug":"Google colab Tips2","date":"2019-07-12T12:37:34.227Z","updated":"2019-07-12T12:37:35.036Z","comments":true,"path":"2019/07/12/Google colab Tips2/","link":"","permalink":"http://yoursite.com/2019/07/12/Google colab Tips2/","excerpt":"","text":"挂载Drive 12from google.colab import drive drive.mount(&apos;/content/drive&apos;) 接着打开链接输入授权码 虚拟机文件下载 12from google.colab import files files.download(&apos;file&quot;) # 同理，file.upload()","categories":[],"tags":[]},{"title":"","slug":"Navicat Tips","date":"2019-07-12T12:37:25.251Z","updated":"2019-07-12T12:37:26.163Z","comments":true,"path":"2019/07/12/Navicat Tips/","link":"","permalink":"http://yoursite.com/2019/07/12/Navicat Tips/","excerpt":"","text":"Ubuntu18安装Navicat乱码解决办法 启动 ./start_navicat 解决字符乱码 12locale -a export LANG=zh_CN.utf8 软件内仍存在乱码解决办法工具—选项—常规—-界面字体 粘贴为Noto Sans Mono CJK TC Regular，保存并推出重启即可","categories":[],"tags":[]},{"title":"","slug":"Navicat Tips2    ERROR 1698 (28000)_ Access denied for user 'root'@'localhost'","date":"2019-07-12T12:37:15.179Z","updated":"2019-07-12T12:37:15.917Z","comments":true,"path":"2019/07/12/Navicat Tips2    ERROR 1698 (28000)_ Access denied for user 'root'@'localhost'/","link":"","permalink":"http://yoursite.com/2019/07/12/Navicat Tips2    ERROR 1698 (28000)_ Access denied for user 'root'@'localhost'/","excerpt":"","text":"ERROR 1698 (28000): Access denied for user ‘root’@’localhost’转载自学习 进入以下文件1sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf 在如下位置，加入skip-grant-tables保存并退出。 重启mysqlservice mysql restart 重新进入mysql 1mysql -u root -p 123use mysql;update user set authentication_string=password(”你的密码“）where user=&quot;root&quot;;flush privileges; 再次进入mysql 12service mysql restartmysql -u root -p 如下修改 12use mysql;select user,plugin from user; 从图中可以看到在执行了select user,plugin from user后，错误原因是因为plugin root的字段是auth_socket，那我们改掉它为下面的mysql_native_password就行了。 12update user set authentication_string=password(&apos;你的密码&apos;),plugin=&apos;mysql_natice_password&apos; where user=&apos;root&apos;;select user,plugin from user; 此时有 最后注释掉之前的输入 1sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf 此时即可正常进入mysql 1mysql -u root -p","categories":[],"tags":[]},{"title":"","slug":"Mysql学习记录","date":"2019-07-12T12:37:04.427Z","updated":"2019-07-12T12:37:05.135Z","comments":true,"path":"2019/07/12/Mysql学习记录/","link":"","permalink":"http://yoursite.com/2019/07/12/Mysql学习记录/","excerpt":"","text":"mysql (内连接，外连接，左连接，右连接，自连接）学习记录 内连接只显示连接过程中交叉的部分 select * from A a inner join B b on a.id = b.id 左连接右连接同属于外连接 select * from A a left join B b on a.id = b.id -- 显示左表全部记录以及左右表同时存在的记录 `select * from A a right join B b on a.id = b.id -- 显示右表全部记录以及左右表同时存在的记录` 为现有表添加主键 alter table my_contacts add column contact_id int not null auto_increment first, add primary key (contact_id); 使用CASE表达式来Updateupdate movie_tableset category =casewhen drama = &#39;T&#39; then &#39;drama&#39;when comedy = &#39;T&#39; then &#39;comedy&#39;else &#39;miscend;","categories":[],"tags":[]},{"title":"","slug":"Tips (1)","date":"2019-07-12T12:36:54.955Z","updated":"2019-07-12T12:36:55.683Z","comments":true,"path":"2019/07/12/Tips (1)/","link":"","permalink":"http://yoursite.com/2019/07/12/Tips (1)/","excerpt":"","text":"pymongo api 1234sheet_weather.update_one(&#123;&apos;_id&apos;: item[&apos;_id&apos;]&#125;, &#123;&apos;$set&apos;: &#123;&apos;HeWeather6.0.daily_forecast.&#123;&#125;.tmp_min&apos;.format(i): int(tmp)&#125;&#125;)sheet_weather.find_one_and_delete(&#123;&apos;_id&apos;:item[&apos;_id&apos;]&#125;,&#123;&apos;HeWeather6.0.daily_forecast.&#123;&#125;.tmp_min&apos;&#125;) {‘_id’: item[‘_id’]}表示需要更新的查询条件，对应_id字段。第二个参数表示要更新的信息，$set 为MongoDB的一个修改器，用于指定一个键并更新键值，若键不存在则创建一个键 常用的修改器还有： $inc 可以对文档的某个值为数字型的键进行增减操作 $unset 用于删除键 $push向文档的某个数组类型的键添加一个数组元素，不过滤重复的数据。添加时，若键存在，则要求键值类型必须为数组；若键不存在，则创建数组类型的键 {&#39;$set&#39;: {&#39;HeWeather6.0.daily_forecast.{}.tmp_min&#39;.format(i): int(tmp)}} url = &#39;https://free-api.heweather.net/s6/weather/forecast?location=&#39;+item[1:14]+&#39;&amp;key=aaaaaaaaaaaaa可以写成 1url = &apos;https://free-api.heweather.net/s6/weather/forecast?location=&#123;&#125;&amp;key=aaaa&apos;.format(item[1:14])","categories":[],"tags":[]},{"title":"","slug":"用API爬取天气预报数据","date":"2019-07-12T12:36:41.180Z","updated":"2019-07-12T15:21:31.508Z","comments":true,"path":"2019/07/12/用API爬取天气预报数据/","link":"","permalink":"http://yoursite.com/2019/07/12/用API爬取天气预报数据/","excerpt":"","text":"使用API爬去天气预报数据 Code123456789101112131415161718192021222324252627282930313233import requestsimport numpyimport reimport time# 加载pymongoimport pymongoclient = pymongo.MongoClient(&apos;localhost&apos;,27017)book_weather = client[&apos;weather&apos;]sheet_weather = book_weather[&apos;sheet_weather_3&apos;]url = &apos;https://cdn.heweather.com/china-city-list.txt&apos;strhtml = requests.get(url)strhtml.encoding = &apos;utf-8&apos;data = strhtml.textdata1 = data.split(&apos;\\n&apos;)for i in range(6): data1.remove(data1[0])for item in data1: # url = &apos;https://free-api.weather.com/v5/forecast?city=&apos;+ item[0:11] +&apos;&amp;key=yourownkey&apos; url = &apos;https://free-api.heweather.net/s6/weather/forecast?location=&#123;&#125;&amp;key=yourownkey&apos;.format(item[1:14]) strhtml = requests.get(url) # print(strhtml) time.sleep(1) dic = strhtml.json() # 向表写入一条数据 sheet_weather.insert_one(dic)import pymongoclient = pymongo.MongoClient(&apos;localhost&apos;,27017)book_weather = client[&apos;weather&apos;]sheet_weather = book_weather[&apos;sheet_weather_3&apos;] 查询未来三天最低气温低于5度的地点 123456789101112131415import pymongoclient = pymongo.MongoClient(&apos;localhost&apos;,27017)book_weather = client[&apos;weather&apos;]sheet_weather = book_weather[&apos;sheet_weather_3&apos;]for item in sheet_weather.find(): for i in range(3): tmp = item[&apos;HeWeather6&apos;][0][&apos;daily_forecast&apos;][i][&apos;tmp_min&apos;] sheet_weather.update_one(&#123;&apos;_id&apos;: item[&apos;_id&apos;]&#125;, &#123;&apos;$set&apos;: &#123;&apos;HeWeather6.0.daily_forecast.&#123;&#125;.tmp_min&apos;.format(i): int(tmp)&#125;&#125;) #sheet_weather.find_one_and_delete(&#123;&apos;_id&apos;:item[&apos;_id&apos;]&#125;,&#123;&apos;HeWeather6.0.daily_forecast.&#123;&#125;.tmp_min&apos;&#125;)for item in sheet_weather.find(&#123;&apos;HeWeather6.0.daily_forecast.tmp_min&apos;:&#123;&apos;$gt&apos;:5&#125;&#125;): print(item[&apos;HeWeather6&apos;][0][&apos;basic&apos;][&apos;location&apos;]) $lt, $lte, $gt, $gte 分别表示&lt; , &lt;=, &gt;, &gt;=","categories":[],"tags":[]},{"title":"","slug":"Tips","date":"2019-07-12T12:36:31.572Z","updated":"2019-07-12T12:36:32.295Z","comments":true,"path":"2019/07/12/Tips/","link":"","permalink":"http://yoursite.com/2019/07/12/Tips/","excerpt":"","text":"以癌症预测为例 0:恶性，1:良性 TP： 真正例，良性被正确预测 TN：真反例，恶性被正确预测 FP：假正例，恶性被预测为良性 FN：假反例，良性被预测为恶性 Accuracy:准确率（TP+TN）/（TP+TN+FP+FN）Precision:查准率 TP/(TP+FP)Recall:查全率 TP/(TP+FN) 12345678import numpy as np arr = np.arange(12).reshape(3,4)print(arr)a = arr[:,::2]print(a)b = arr[::1,:]print(b) 123456789[[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]][[ 0 2] [ 4 6] [ 8 10]][[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]]","categories":[],"tags":[]},{"title":"","slug":"T","date":"2019-07-12T12:36:10.659Z","updated":"2019-07-12T12:36:13.088Z","comments":true,"path":"2019/07/12/T/","link":"","permalink":"http://yoursite.com/2019/07/12/T/","excerpt":"","text":"operator.itemgetter operator 12sorted = sorted(data,key = operator.itemgetter(n))---operator.itemgetter(n)返回位置n上的元素 zip `np.c_ np.r_ np.meshgrid` x = np.arange(1,3,1) y = np.arange(4,8,1) xx,yy = np.meshgrid(x,y) print(xx,yy ) print(xx.ravel()) print(yy.ravel()) 1234567891011121314151617x = np.linespace(1,10,10)y = np.linespace(2,8,6)x1,x2 = np.meshgrid(x,y) #返回list,有两个元素,第一个元素是X轴的取值,第二个元素是Y轴的取值》》》[[ 1. 2. 3. 4. 5. 6. 7. 8. 9. 10.] [ 1. 2. 3. 4. 5. 6. 7. 8. 9. 10.] [ 1. 2. 3. 4. 5. 6. 7. 8. 9. 10.] [ 1. 2. 3. 4. 5. 6. 7. 8. 9. 10.] [ 1. 2. 3. 4. 5. 6. 7. 8. 9. 10.] [ 1. 2. 3. 4. 5. 6. 7. 8. 9. 10.] [ 1. 2. 3. 4. 5. 6. 7. 8. 9. 10.]] [[2. 2. 2. 2. 2. 2. 2. 2. 2. 2.] [3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [4. 4. 4. 4. 4. 4. 4. 4. 4. 4.] [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.] [6. 6. 6. 6. 6. 6. 6. 6. 6. 6.] [7. 7. 7. 7. 7. 7. 7. 7. 7. 7.] [8. 8. 8. 8. 8. 8. 8. 8. 8. 8.]] pandas 计算偏度和峰度1234567891011121314%matplotlib inlineimport pandas as pdfrom sklearn.datasets import load_iris import matplotlib.pyplot as pltimport seaborn as snsiris = load_iris()x = iris.datay = iris.targetxx.columnsprint(&quot;鸢尾花长度的偏度：%f&quot; % xx[&apos;sepal length (cm)&apos;].skew())print(&quot;鸢尾花长度的峰度：%f&quot; % xx[&apos;sepal length (cm)&apos;].kurt())","categories":[],"tags":[]},{"title":"MNIST数据集的读取","slug":"MNIST数据集的读取","date":"2019-07-12T03:38:04.442Z","updated":"2019-07-12T08:27:18.471Z","comments":true,"path":"2019/07/12/MNIST数据集的读取/","link":"","permalink":"http://yoursite.com/2019/07/12/MNIST数据集的读取/","excerpt":"","text":"下载MNIST 数据集，并保存到home/wang/文档/Linux_python/ML/Python_ml test/MNIST_data/mldata文件夹下123456789101112from sklearn.datasets import fetch_mldatamnist = fetch_mldata(&apos;mnist-original&apos;, data_home = &apos;/home/wang/文档/Linux_python/ML/Python_ml test/MNIST_data&apos;)X = mnist[&apos;data&apos;]y = mnist[&apos;target&apos;]print(X)print(y)from sklearn.model_selection import train_test_splitX_train,X_test,y_train,y_test = train_test_split(X,y)","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/categories/Machine-Learning/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/tags/ML/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-07-12T02:06:54.964Z","updated":"2019-07-12T02:06:54.964Z","comments":true,"path":"2019/07/12/hello-world/","link":"","permalink":"http://yoursite.com/2019/07/12/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}