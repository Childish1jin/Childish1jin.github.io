{"meta":{"title":"Barry's blog","subtitle":"Run!!!","description":"run barry, run!","author":"Barry Wang","url":"http://yoursite.com","root":"/"},"pages":[{"title":"about","date":"2019-07-12T08:27:37.000Z","updated":"2019-07-12T08:27:37.233Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""},{"title":"����","date":"2019-07-12T08:22:33.000Z","updated":"2019-07-12T08:23:15.497Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"��ǩ","date":"2019-07-12T08:26:06.000Z","updated":"2019-07-12T08:26:34.086Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"post_name","slug":"post-name","date":"2019-08-26T09:54:31.000Z","updated":"2019-08-26T09:54:31.390Z","comments":true,"path":"2019/08/26/post-name/","link":"","permalink":"http://yoursite.com/2019/08/26/post-name/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Myblog","slug":"Myblog","date":"2019-08-26T08:32:28.000Z","updated":"2019-08-26T08:32:28.347Z","comments":true,"path":"2019/08/26/Myblog/","link":"","permalink":"http://yoursite.com/2019/08/26/Myblog/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"【面向数据科学家的实用统计学】1","slug":"【面向数据科学家的实用统计学】1","date":"2019-08-26T07:33:56.966Z","updated":"2019-08-26T10:00:46.355Z","comments":true,"path":"2019/08/26/【面向数据科学家的实用统计学】1/","link":"","permalink":"http://yoursite.com/2019/08/26/【面向数据科学家的实用统计学】1/","excerpt":"","text":"1234567891011121314151617181920# 绘图案例 an example of matplotlib%matplotlib inlineimport numpy as npimport matplotlib.pyplot as pltfrom scipy.special import jnfrom IPython.display import display, clear_outputimport timex = np.linspace(0,5)f, ax = plt.subplots()ax.set_title(\"Bessel functions\")for n in range(1,10): time.sleep(1) ax.plot(x, jn(x,n)) clear_output(wait=True) display(f)# close the figure at the end, so we don't get a duplicate# of the last plotplt.close()","categories":[],"tags":[{"name":"统计学","slug":"统计学","permalink":"http://yoursite.com/tags/统计学/"}]},{"title":"kaggle house prices XGBOOST","slug":"house prices XGBOOST","date":"2019-08-10T02:55:47.811Z","updated":"2019-08-26T08:40:01.242Z","comments":true,"path":"2019/08/10/house prices XGBOOST/","link":"","permalink":"http://yoursite.com/2019/08/10/house prices XGBOOST/","excerpt":"12import os print(os.listdir('../input')) [&apos;sample_submission.csv&apos;, &apos;test.csv&apos;, &apos;data_description.txt&apos;, &apos;train.csv&apos;]1!ls __notebook_source__.ipynb12345678910111213141516171819import warningswarnings.filterwarnings(action= 'ignore')import matplotlib.pyplot as plt import seaborn as sns #plt.style.use('fivethirtyeight')from sklearn.preprocessing import StandardScalerimport numpy as npimport pandas as pd from sklearn.metrics import mean_squared_errorfrom sklearn.model_selection import KFoldfrom mxnet import autograd,nd from mxnet.gluon import nn,loss as gloss,data as gdatafrom mxnet import gluon#import d2lzh as d2lfrom sklearn.model_selection import train_test_splitfrom xgboost import XGBRegressorfrom sklearn.metrics import mean_squared_error%matplotlib inline","text":"12import os print(os.listdir('../input')) [&apos;sample_submission.csv&apos;, &apos;test.csv&apos;, &apos;data_description.txt&apos;, &apos;train.csv&apos;]1!ls __notebook_source__.ipynb12345678910111213141516171819import warningswarnings.filterwarnings(action= 'ignore')import matplotlib.pyplot as plt import seaborn as sns #plt.style.use('fivethirtyeight')from sklearn.preprocessing import StandardScalerimport numpy as npimport pandas as pd from sklearn.metrics import mean_squared_errorfrom sklearn.model_selection import KFoldfrom mxnet import autograd,nd from mxnet.gluon import nn,loss as gloss,data as gdatafrom mxnet import gluon#import d2lzh as d2lfrom sklearn.model_selection import train_test_splitfrom xgboost import XGBRegressorfrom sklearn.metrics import mean_squared_error%matplotlib inline 12train_data = pd.read_csv('../input/train.csv')train_data.head() Id MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape LandContour Utilities ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold YrSold SaleType SaleCondition SalePrice 0 1 60 RL 65.0 8450 Pave NaN Reg Lvl AllPub ... 0 NaN NaN NaN 0 2 2008 WD Normal 208500 1 2 20 RL 80.0 9600 Pave NaN Reg Lvl AllPub ... 0 NaN NaN NaN 0 5 2007 WD Normal 181500 2 3 60 RL 68.0 11250 Pave NaN IR1 Lvl AllPub ... 0 NaN NaN NaN 0 9 2008 WD Normal 223500 3 4 70 RL 60.0 9550 Pave NaN IR1 Lvl AllPub ... 0 NaN NaN NaN 0 2 2006 WD Abnorml 140000 4 5 60 RL 84.0 14260 Pave NaN IR1 Lvl AllPub ... 0 NaN NaN NaN 0 12 2008 WD Normal 250000 5 rows × 81 columns 12test_data = pd.read_csv('../input/test.csv')test_data.head() Id MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape LandContour Utilities ... ScreenPorch PoolArea PoolQC Fence MiscFeature MiscVal MoSold YrSold SaleType SaleCondition 0 1461 20 RH 80.0 11622 Pave NaN Reg Lvl AllPub ... 120 0 NaN MnPrv NaN 0 6 2010 WD Normal 1 1462 20 RL 81.0 14267 Pave NaN IR1 Lvl AllPub ... 0 0 NaN NaN Gar2 12500 6 2010 WD Normal 2 1463 60 RL 74.0 13830 Pave NaN IR1 Lvl AllPub ... 0 0 NaN MnPrv NaN 0 3 2010 WD Normal 3 1464 60 RL 78.0 9978 Pave NaN IR1 Lvl AllPub ... 0 0 NaN NaN NaN 0 6 2010 WD Normal 4 1465 120 RL 43.0 5005 Pave NaN IR1 HLS AllPub ... 144 0 NaN NaN NaN 0 1 2010 WD Normal 5 rows × 80 columns 12print('train shape&#123;&#125;'.format(train_data.shape))print('test shape&#123;&#125;'.format(test_data.shape)) train shape(1460, 81) test shape(1459, 80)1train_data.isnull().sum() Id 0 MSSubClass 0 MSZoning 0 LotFrontage 259 LotArea 0 Street 0 Alley 1369 LotShape 0 LandContour 0 Utilities 0 LotConfig 0 LandSlope 0 Neighborhood 0 Condition1 0 Condition2 0 BldgType 0 HouseStyle 0 OverallQual 0 OverallCond 0 YearBuilt 0 YearRemodAdd 0 RoofStyle 0 RoofMatl 0 Exterior1st 0 Exterior2nd 0 MasVnrType 8 MasVnrArea 8 ExterQual 0 ExterCond 0 Foundation 0 ... BedroomAbvGr 0 KitchenAbvGr 0 KitchenQual 0 TotRmsAbvGrd 0 Functional 0 Fireplaces 0 FireplaceQu 690 GarageType 81 GarageYrBlt 81 GarageFinish 81 GarageCars 0 GarageArea 0 GarageQual 81 GarageCond 81 PavedDrive 0 WoodDeckSF 0 OpenPorchSF 0 EnclosedPorch 0 3SsnPorch 0 ScreenPorch 0 PoolArea 0 PoolQC 1453 Fence 1179 MiscFeature 1406 MiscVal 0 MoSold 0 YrSold 0 SaleType 0 SaleCondition 0 SalePrice 0 Length: 81, dtype: int64123import os print(os.listdir('../input')) [&apos;sample_submission.csv&apos;, &apos;test.csv&apos;, &apos;data_description.txt&apos;, &apos;train.csv&apos;]12train_data.drop('Id',axis = 1 ,inplace = True)test_data.drop('Id',axis = 1 ,inplace= True) 1train_data.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } ​ MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape LandContour Utilities LotConfig ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold YrSold SaleType SaleCondition SalePrice 0 60 RL 65.0 8450 Pave NaN Reg Lvl AllPub Inside ... 0 NaN NaN NaN 0 2 2008 WD Normal 208500 1 20 RL 80.0 9600 Pave NaN Reg Lvl AllPub FR2 ... 0 NaN NaN NaN 0 5 2007 WD Normal 181500 2 60 RL 68.0 11250 Pave NaN IR1 Lvl AllPub Inside ... 0 NaN NaN NaN 0 9 2008 WD Normal 223500 3 70 RL 60.0 9550 Pave NaN IR1 Lvl AllPub Corner ... 0 NaN NaN NaN 0 2 2006 WD Abnorml 140000 4 60 RL 84.0 14260 Pave NaN IR1 Lvl AllPub FR2 ... 0 NaN NaN NaN 0 12 2008 WD Normal 250000 5 rows × 80 columns 1train_data.describe().T .dataframe tbody tr th:only-of-type { vertical-align: middle; } ​ count mean std min 25% 50% 75% max MSSubClass 1460.0 56.897260 42.300571 20.0 20.00 50.0 70.00 190.0 LotFrontage 1201.0 70.049958 24.284752 21.0 59.00 69.0 80.00 313.0 LotArea 1460.0 10516.828082 9981.264932 1300.0 7553.50 9478.5 11601.50 215245.0 OverallQual 1460.0 6.099315 1.382997 1.0 5.00 6.0 7.00 10.0 OverallCond 1460.0 5.575342 1.112799 1.0 5.00 5.0 6.00 9.0 YearBuilt 1460.0 1971.267808 30.202904 1872.0 1954.00 1973.0 2000.00 2010.0 YearRemodAdd 1460.0 1984.865753 20.645407 1950.0 1967.00 1994.0 2004.00 2010.0 MasVnrArea 1452.0 103.685262 181.066207 0.0 0.00 0.0 166.00 1600.0 BsmtFinSF1 1460.0 443.639726 456.098091 0.0 0.00 383.5 712.25 5644.0 BsmtFinSF2 1460.0 46.549315 161.319273 0.0 0.00 0.0 0.00 1474.0 BsmtUnfSF 1460.0 567.240411 441.866955 0.0 223.00 477.5 808.00 2336.0 TotalBsmtSF 1460.0 1057.429452 438.705324 0.0 795.75 991.5 1298.25 6110.0 1stFlrSF 1460.0 1162.626712 386.587738 334.0 882.00 1087.0 1391.25 4692.0 2ndFlrSF 1460.0 346.992466 436.528436 0.0 0.00 0.0 728.00 2065.0 LowQualFinSF 1460.0 5.844521 48.623081 0.0 0.00 0.0 0.00 572.0 GrLivArea 1460.0 1515.463699 525.480383 334.0 1129.50 1464.0 1776.75 5642.0 BsmtFullBath 1460.0 0.425342 0.518911 0.0 0.00 0.0 1.00 3.0 BsmtHalfBath 1460.0 0.057534 0.238753 0.0 0.00 0.0 0.00 2.0 FullBath 1460.0 1.565068 0.550916 0.0 1.00 2.0 2.00 3.0 HalfBath 1460.0 0.382877 0.502885 0.0 0.00 0.0 1.00 2.0 BedroomAbvGr 1460.0 2.866438 0.815778 0.0 2.00 3.0 3.00 8.0 KitchenAbvGr 1460.0 1.046575 0.220338 0.0 1.00 1.0 1.00 3.0 TotRmsAbvGrd 1460.0 6.517808 1.625393 2.0 5.00 6.0 7.00 14.0 Fireplaces 1460.0 0.613014 0.644666 0.0 0.00 1.0 1.00 3.0 GarageYrBlt 1379.0 1978.506164 24.689725 1900.0 1961.00 1980.0 2002.00 2010.0 GarageCars 1460.0 1.767123 0.747315 0.0 1.00 2.0 2.00 4.0 GarageArea 1460.0 472.980137 213.804841 0.0 334.50 480.0 576.00 1418.0 WoodDeckSF 1460.0 94.244521 125.338794 0.0 0.00 0.0 168.00 857.0 OpenPorchSF 1460.0 46.660274 66.256028 0.0 0.00 25.0 68.00 547.0 EnclosedPorch 1460.0 21.954110 61.119149 0.0 0.00 0.0 0.00 552.0 3SsnPorch 1460.0 3.409589 29.317331 0.0 0.00 0.0 0.00 508.0 ScreenPorch 1460.0 15.060959 55.757415 0.0 0.00 0.0 0.00 480.0 PoolArea 1460.0 2.758904 40.177307 0.0 0.00 0.0 0.00 738.0 MiscVal 1460.0 43.489041 496.123024 0.0 0.00 0.0 0.00 15500.0 MoSold 1460.0 6.321918 2.703626 1.0 5.00 6.0 8.00 12.0 YrSold 1460.0 2007.815753 1.328095 2006.0 2007.00 2008.0 2009.00 2010.0 SalePrice 1460.0 180921.195890 79442.502883 34900.0 129975.00 163000.0 214000.00 755000.0 1234plt.scatter(train_data['GrLivArea'],train_data['SalePrice'],label = 'area vs price');plt.xlabel('GrLivArea')plt.ylabel('SalePrice')plt.legend(loc = 'lower right'); 1train_data[train_data['Alley'].isnull()].head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape LandContour Utilities LotConfig ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold YrSold SaleType SaleCondition SalePrice 0 60 RL 65.0 8450 Pave NaN Reg Lvl AllPub Inside ... 0 NaN NaN NaN 0 2 2008 WD Normal 208500 1 20 RL 80.0 9600 Pave NaN Reg Lvl AllPub FR2 ... 0 NaN NaN NaN 0 5 2007 WD Normal 181500 2 60 RL 68.0 11250 Pave NaN IR1 Lvl AllPub Inside ... 0 NaN NaN NaN 0 9 2008 WD Normal 223500 3 70 RL 60.0 9550 Pave NaN IR1 Lvl AllPub Corner ... 0 NaN NaN NaN 0 2 2006 WD Abnorml 140000 4 60 RL 84.0 14260 Pave NaN IR1 Lvl AllPub FR2 ... 0 NaN NaN NaN 0 12 2008 WD Normal 250000 5 rows × 80 columns 1234list = []for i in train_data.columns: list.append(i)print(list) [&apos;MSSubClass&apos;, &apos;MSZoning&apos;, &apos;LotFrontage&apos;, &apos;LotArea&apos;, &apos;Street&apos;, &apos;Alley&apos;, &apos;LotShape&apos;, &apos;LandContour&apos;, &apos;Utilities&apos;, &apos;LotConfig&apos;, &apos;LandSlope&apos;, &apos;Neighborhood&apos;, &apos;Condition1&apos;, &apos;Condition2&apos;, &apos;BldgType&apos;, &apos;HouseStyle&apos;, &apos;OverallQual&apos;, &apos;OverallCond&apos;, &apos;YearBuilt&apos;, &apos;YearRemodAdd&apos;, &apos;RoofStyle&apos;, &apos;RoofMatl&apos;, &apos;Exterior1st&apos;, &apos;Exterior2nd&apos;, &apos;MasVnrType&apos;, &apos;MasVnrArea&apos;, &apos;ExterQual&apos;, &apos;ExterCond&apos;, &apos;Foundation&apos;, &apos;BsmtQual&apos;, &apos;BsmtCond&apos;, &apos;BsmtExposure&apos;, &apos;BsmtFinType1&apos;, &apos;BsmtFinSF1&apos;, &apos;BsmtFinType2&apos;, &apos;BsmtFinSF2&apos;, &apos;BsmtUnfSF&apos;, &apos;TotalBsmtSF&apos;, &apos;Heating&apos;, &apos;HeatingQC&apos;, &apos;CentralAir&apos;, &apos;Electrical&apos;, &apos;1stFlrSF&apos;, &apos;2ndFlrSF&apos;, &apos;LowQualFinSF&apos;, &apos;GrLivArea&apos;, &apos;BsmtFullBath&apos;, &apos;BsmtHalfBath&apos;, &apos;FullBath&apos;, &apos;HalfBath&apos;, &apos;BedroomAbvGr&apos;, &apos;KitchenAbvGr&apos;, &apos;KitchenQual&apos;, &apos;TotRmsAbvGrd&apos;, &apos;Functional&apos;, &apos;Fireplaces&apos;, &apos;FireplaceQu&apos;, &apos;GarageType&apos;, &apos;GarageYrBlt&apos;, &apos;GarageFinish&apos;, &apos;GarageCars&apos;, &apos;GarageArea&apos;, &apos;GarageQual&apos;, &apos;GarageCond&apos;, &apos;PavedDrive&apos;, &apos;WoodDeckSF&apos;, &apos;OpenPorchSF&apos;, &apos;EnclosedPorch&apos;, &apos;3SsnPorch&apos;, &apos;ScreenPorch&apos;, &apos;PoolArea&apos;, &apos;PoolQC&apos;, &apos;Fence&apos;, &apos;MiscFeature&apos;, &apos;MiscVal&apos;, &apos;MoSold&apos;, &apos;YrSold&apos;, &apos;SaleType&apos;, &apos;SaleCondition&apos;, &apos;SalePrice&apos;] 删除缺失值过多的列 12dropped_columns = ['Alley','PoolQC','Fence','MiscFeature']train_data.drop(dropped_columns,axis = 1 ,inplace= True) 12test_data.drop(dropped_columns,axis = 1 ,inplace= True)test_data.shape (1459, 75)1234y = train_data['SalePrice'].reset_index(drop =True)train_features = train_data.drop('SalePrice',axis = 1)features = pd.concat([train_features,test_data]).reset_index(drop = True)labels =train_data['SalePrice'] 1print('删除缺失值后，feature shape为：&#123;&#125;'.format(features.shape)) 删除缺失值后，feature shape为：(2919, 75)feature 存在空值列 1features.isnull().sum()[features.isnull().sum() &gt; 0] MSZoning 4 LotFrontage 486 Utilities 2 Exterior1st 1 Exterior2nd 1 MasVnrType 24 MasVnrArea 23 BsmtQual 81 BsmtCond 82 BsmtExposure 82 BsmtFinType1 79 BsmtFinSF1 1 BsmtFinType2 80 BsmtFinSF2 1 BsmtUnfSF 1 TotalBsmtSF 1 Electrical 1 BsmtFullBath 2 BsmtHalfBath 2 KitchenQual 1 Functional 2 FireplaceQu 1420 GarageType 157 GarageYrBlt 159 GarageFinish 159 GarageCars 1 GarageArea 1 GarageQual 159 GarageCond 159 SaleType 1 dtype: int64123456789dict = &#123;&#125;for i,v in enumerate(features['Exterior1st']): if v not in dict: dict[v] = 1 else: dict[v] +=1 list = [x for x in dict.keys()] 123features['Exterior1st'][features['Exterior1st'] == 'Vinylsd'] = 'VinylSd'features['Exterior1st'] = features['Exterior1st'].fillna('VinylSd')features['Exterior1st'].mode() 0 VinylSd dtype: object1features.mode()['MSSubClass'][0] 20123features['Exterior2nd'] = features['Exterior2nd'].fillna(features['Exterior2nd'].mode()[0])features['SaleType'] = features['SaleType'].fillna(features['SaleType'].mode()[0])features['MSSubClass'] = features.fillna(features.mode()['MSSubClass'][0]) 12345def type_change(feature,needed,type): for i in needed: feature[i] = feature[i].astype(type)type_change(features,['MSSubClass','YrSold','MoSold'],type = 'str') 12for column in ['Functional','Electrical','KitchenQual']: features[column].fillna(features.mode()[column][0]) 123for column in ['Exterior1st','Exterior2nd','SaleType']: if features[column].isnull().sum() == 0: print('T') T T T 检验是否有空值 1features.isnull().sum()[features.isnull().sum() &gt; 0] MSZoning 4 LotFrontage 486 Utilities 2 MasVnrType 24 MasVnrArea 23 BsmtQual 81 BsmtCond 82 BsmtExposure 82 BsmtFinType1 79 BsmtFinSF1 1 BsmtFinType2 80 BsmtFinSF2 1 BsmtUnfSF 1 TotalBsmtSF 1 Electrical 1 BsmtFullBath 2 BsmtHalfBath 2 KitchenQual 1 Functional 2 FireplaceQu 1420 GarageType 157 GarageYrBlt 159 GarageFinish 159 GarageCars 1 GarageArea 1 GarageQual 159 GarageCond 159 dtype: int641features['MSZoning'] = features.groupby('MSSubClass')['MSZoning'].transform(lambda x : x.fillna(x.mode()[0])) 定性定量数据 1234567891011121314objects = []for i in features.columns: if features[i].dtype == object: objects.append(i)features.update(features[objects].fillna('None'))features['LotFrontage'] = features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']numerics = []for i in features.columns: if features[i].dtype in numeric_dtypes: numerics.append(i)features.update(features[numerics].fillna(0)) 1print(objects,'\\n',numerics) [&apos;MSSubClass&apos;, &apos;MSZoning&apos;, &apos;Street&apos;, &apos;LotShape&apos;, &apos;LandContour&apos;, &apos;Utilities&apos;, &apos;LotConfig&apos;, &apos;LandSlope&apos;, &apos;Neighborhood&apos;, &apos;Condition1&apos;, &apos;Condition2&apos;, &apos;BldgType&apos;, &apos;HouseStyle&apos;, &apos;RoofStyle&apos;, &apos;RoofMatl&apos;, &apos;Exterior1st&apos;, &apos;Exterior2nd&apos;, &apos;MasVnrType&apos;, &apos;ExterQual&apos;, &apos;ExterCond&apos;, &apos;Foundation&apos;, &apos;BsmtQual&apos;, &apos;BsmtCond&apos;, &apos;BsmtExposure&apos;, &apos;BsmtFinType1&apos;, &apos;BsmtFinType2&apos;, &apos;Heating&apos;, &apos;HeatingQC&apos;, &apos;CentralAir&apos;, &apos;Electrical&apos;, &apos;KitchenQual&apos;, &apos;Functional&apos;, &apos;FireplaceQu&apos;, &apos;GarageType&apos;, &apos;GarageFinish&apos;, &apos;GarageQual&apos;, &apos;GarageCond&apos;, &apos;PavedDrive&apos;, &apos;MoSold&apos;, &apos;YrSold&apos;, &apos;SaleType&apos;, &apos;SaleCondition&apos;] [&apos;LotFrontage&apos;, &apos;LotArea&apos;, &apos;OverallQual&apos;, &apos;OverallCond&apos;, &apos;YearBuilt&apos;, &apos;YearRemodAdd&apos;, &apos;MasVnrArea&apos;, &apos;BsmtFinSF1&apos;, &apos;BsmtFinSF2&apos;, &apos;BsmtUnfSF&apos;, &apos;TotalBsmtSF&apos;, &apos;1stFlrSF&apos;, &apos;2ndFlrSF&apos;, &apos;LowQualFinSF&apos;, &apos;GrLivArea&apos;, &apos;BsmtFullBath&apos;, &apos;BsmtHalfBath&apos;, &apos;FullBath&apos;, &apos;HalfBath&apos;, &apos;BedroomAbvGr&apos;, &apos;KitchenAbvGr&apos;, &apos;TotRmsAbvGrd&apos;, &apos;Fireplaces&apos;, &apos;GarageYrBlt&apos;, &apos;GarageCars&apos;, &apos;GarageArea&apos;, &apos;WoodDeckSF&apos;, &apos;OpenPorchSF&apos;, &apos;EnclosedPorch&apos;, &apos;3SsnPorch&apos;, &apos;ScreenPorch&apos;, &apos;PoolArea&apos;, &apos;MiscVal&apos;]123from scipy.stats import skew # for some statistics # 计算数据集的偏度from scipy.special import boxcox1pfrom scipy.stats import boxcox_normmax scipy.stats.skewscipy.special.boxcox1p box-cox变换 1234567891011121314numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']numerics2 = []for i in features.columns: if features[i].dtype in numeric_dtypes: numerics2.append(i)skew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)# 偏度&gt;0.5high_skew = skew_features[skew_features &gt; 0.5]skew_index = high_skew.indexfor i in skew_index: features[i] = boxcox1p(features[i], boxcox_normmax(features[i] + 1)) 1high_skew MiscVal 21.947195 PoolArea 16.898328 LotArea 12.822431 LowQualFinSF 12.088761 3SsnPorch 11.376065 KitchenAbvGr 4.302254 BsmtFinSF2 4.146143 EnclosedPorch 4.003891 ScreenPorch 3.946694 BsmtHalfBath 3.931594 MasVnrArea 2.613592 OpenPorchSF 2.535114 WoodDeckSF 1.842433 LotFrontage 1.505704 1stFlrSF 1.469604 BsmtFinSF1 1.425230 GrLivArea 1.269358 TotalBsmtSF 1.156894 BsmtUnfSF 0.919339 2ndFlrSF 0.861675 TotRmsAbvGrd 0.758367 Fireplaces 0.733495 HalfBath 0.694566 BsmtFullBath 0.624832 OverallCond 0.570312 dtype: float641features.isnull().sum()[features.isnull().sum() &gt; 0] Series([], dtype: int64) 增加新特征 123456789101112# 建造日期+ 改造日期features['YrBltAndRemod'] = (features['YearBuilt'] + features['YearRemodAdd']) /2# 总面积features['TotalSF'] = features['TotalBsmtSF'] + features['1stFlrSF'] + features['2ndFlrSF']features['Total_sqr_footage'] = (features['BsmtFinSF1'] + features['BsmtFinSF2'] + features['1stFlrSF'] + features['2ndFlrSF'])features['Total_Bathrooms'] = (features['FullBath'] + (0.5 * features['HalfBath']) + features['BsmtFullBath'] + (0.5 * features['BsmtHalfBath']))features['Total_porch_sf'] = (features['OpenPorchSF'] + features['3SsnPorch'] + features['EnclosedPorch'] + features['ScreenPorch'] + features['WoodDeckSF']) 12345features['haspool'] = features['PoolArea'].apply(lambda x: 1 if x &gt; 0 else 0)features['has2ndfloor'] = features['2ndFlrSF'].apply(lambda x: 1 if x &gt; 0 else 0)features['hasgarage'] = features['GarageArea'].apply(lambda x: 1 if x &gt; 0 else 0)features['hasbsmt'] = features['TotalBsmtSF'].apply(lambda x: 1 if x &gt; 0 else 0)features['hasfireplace'] = features['Fireplaces'].apply(lambda x: 1 if x &gt; 0 else 0) 1features.shape (2919, 85)12final_features = pd.get_dummies(features).reset_index(drop = True)print('最终拥有的特征个数为：&#123;&#125;'.format(final_features.shape[1])) 最终拥有的特征个数为：329 划分训练，和提交的数据 123X = final_features.iloc[:len(y),:]X_sub = final_features.iloc[len(y):,:]X.shape,y.shape,X_sub.shape ((1460, 329), (1460,), (1459, 329))1234n_train = X.shape[0]train_features = nd.array(X)test_features = nd.array(X_sub)train_labels = nd.array(y).reshape(-1,1) 12model = XGBRegressor()model.fit(X,y,verbose = True) [02:43:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. XGBRegressor(base_score=0.5, booster=&apos;gbtree&apos;, colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1, gamma=0, importance_type=&apos;gain&apos;, learning_rate=0.1, max_delta_step=0, max_depth=3, min_child_weight=1, missing=None, n_estimators=100, n_jobs=1, nthread=None, objective=&apos;reg:linear&apos;, random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, silent=None, subsample=1, verbosity=1)1test_data = pd.read_csv('../input/test.csv') 123test_preds = model.predict(X_sub)output = pd.DataFrame(&#123;'Id':test_data.Id,'SalePrice': test_preds&#125;)output.to_csv('submission.csv',index=False) 123456my_model1 = XGBRegressor(n_estimators=1000, learning_rate=0.05)my_model1.fit(X, y)test_preds1 = my_model1.predict(X_sub)output = pd.DataFrame(&#123;'Id':test_data.Id,'SalePrice': test_preds1&#125;)output.to_csv('submission1.csv',index=False) [02:43:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.","categories":[],"tags":[{"name":"kaggle","slug":"kaggle","permalink":"http://yoursite.com/tags/kaggle/"}]},{"title":"Mxnet手写线性回归","slug":"Mxnet手写线性回归","date":"2019-08-09T02:37:49.562Z","updated":"2019-08-09T03:13:42.100Z","comments":true,"path":"2019/08/09/Mxnet手写线性回归/","link":"","permalink":"http://yoursite.com/2019/08/09/Mxnet手写线性回归/","excerpt":"123456789101112131415161718192021222324252627# 生成数据集num_inputs = 2num_examples = 1000true_w = [2,-3.4]true_b = 4.2features = nd.random.normal(scale = 1, shape = (num_examples, num_inputs))labels = true_w[0] * features[:,0] + true_w[1] * features[:,1] + true_blabels += nd.random.normal(scale = 0.01, shape = labels.shape)# 绘制第二个特征与标签的散点图# def use_svg_display():# display.set_matplotlib_formats('svg')# def set_figsize(figsize = (3.5,2.5)):# use_svg_display()# plt.rcParams['figure.figsize'] = figsize# set_figsize()# plt.scatter(features[:,1].asnumpy(),labels.asnumpy());# Mini_batch def data_iter(batch_size,features,labels): num_examples = len(features) indice = list(range(num_examples)) random.shuffle(indice) # 样本的读取顺序随机 for i in range(0, num_examples, batch_size): j = nd.array(indice[i:min(i + batch_size,num_examples)]) yield features.take(j), labels.take(j)","text":"123456789101112131415161718192021222324252627# 生成数据集num_inputs = 2num_examples = 1000true_w = [2,-3.4]true_b = 4.2features = nd.random.normal(scale = 1, shape = (num_examples, num_inputs))labels = true_w[0] * features[:,0] + true_w[1] * features[:,1] + true_blabels += nd.random.normal(scale = 0.01, shape = labels.shape)# 绘制第二个特征与标签的散点图# def use_svg_display():# display.set_matplotlib_formats('svg')# def set_figsize(figsize = (3.5,2.5)):# use_svg_display()# plt.rcParams['figure.figsize'] = figsize# set_figsize()# plt.scatter(features[:,1].asnumpy(),labels.asnumpy());# Mini_batch def data_iter(batch_size,features,labels): num_examples = len(features) indice = list(range(num_examples)) random.shuffle(indice) # 样本的读取顺序随机 for i in range(0, num_examples, batch_size): j = nd.array(indice[i:min(i + batch_size,num_examples)]) yield features.take(j), labels.take(j) 123456789101112131415161718192021222324252627282930313233343536# 初始化模型参数w = nd.random.normal(scale = 0.01, shape = (num_inputs, 1))b = nd.zeros(shape = (1,))w.attach_grad()b.attach_grad()def linreg(X,w,b): return (nd.dot(X,w) + b)def squared_loss(y_hat, y): return (y_hat -y.reshape(y_hat.shape)) **2 /2# 定义优化算法def sgd(params , lr, batch_size): for param in params: param[:] = param - lr* param.grad / batch_size # 定义模型lr = 0.03num_epochs = 3net = linregloss = squared_lossbatch_size = 10for epoch in range(num_epochs): for X, y in data_iter(batch_size,features, labels): with autograd.record(): l = loss(net(X,w,b),y) l.backward() sgd([w,b],lr,batch_size) train_l = loss(net(features,w,b),labels) print('epoch %d, loss %f' % (epoch +1,train_l.mean().asnumpy()),1)","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/categories/Machine-Learning/"}],"tags":[{"name":"MXNET","slug":"MXNET","permalink":"http://yoursite.com/tags/MXNET/"}]},{"title":"【特征工程入门与实践】Chapter 2","slug":"【特征工程入门与实践】Chapter 2","date":"2019-08-05T03:55:52.844Z","updated":"2019-08-09T03:15:12.588Z","comments":true,"path":"2019/08/05/【特征工程入门与实践】Chapter 2/","link":"","permalink":"http://yoursite.com/2019/08/05/【特征工程入门与实践】Chapter 2/","excerpt":"特征理解123456import pandas as pdimport numpy as npimport matplotlib.pyplot as plt import seaborn as sns %matplotlib inline plt.style.use('fivethirtyeight') 1salary_ranges = pd.read_csv('Salary_Ranges_by_Job_Classification.csv') 1salary_ranges.head()","text":"特征理解123456import pandas as pdimport numpy as npimport matplotlib.pyplot as plt import seaborn as sns %matplotlib inline plt.style.use('fivethirtyeight') 1salary_ranges = pd.read_csv('Salary_Ranges_by_Job_Classification.csv') 1salary_ranges.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } SetID Job Code Eff Date Sal End Date Salary SetID Sal Plan Grade Step Biweekly High Rate Biweekly Low Rate Union Code Extended Step Pay Type 0 COMMN 0109 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 $0.00 $0.00 330 0 C 1 COMMN 0110 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 $15.00 $15.00 323 0 D 2 COMMN 0111 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 $25.00 $25.00 323 0 D 3 COMMN 0112 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 $50.00 $50.00 323 0 D 4 COMMN 0114 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 $100.00 $100.00 323 0 M 1salary_ranges.columns Index([&apos;SetID&apos;, &apos;Job Code&apos;, &apos;Eff Date&apos;, &apos;Sal End Date&apos;, &apos;Salary SetID&apos;, &apos;Sal Plan&apos;, &apos;Grade&apos;, &apos;Step&apos;, &apos;Biweekly High Rate&apos;, &apos;Biweekly Low Rate&apos;, &apos;Union Code&apos;, &apos;Extended Step&apos;, &apos;Pay Type&apos;], dtype=&apos;object&apos;)1salary_ranges.info() &lt;class &apos;pandas.core.frame.DataFrame&apos;&gt; RangeIndex: 1356 entries, 0 to 1355 Data columns (total 13 columns): SetID 1356 non-null object Job Code 1356 non-null object Eff Date 1356 non-null object Sal End Date 1356 non-null object Salary SetID 1356 non-null object Sal Plan 1356 non-null object Grade 1356 non-null object Step 1356 non-null int64 Biweekly High Rate 1356 non-null object Biweekly Low Rate 1356 non-null object Union Code 1356 non-null int64 Extended Step 1356 non-null int64 Pay Type 1356 non-null object dtypes: int64(3), object(10) memory usage: 137.8+ KB1salary_ranges.isnull().sum() SetID 0 Job Code 0 Eff Date 0 Sal End Date 0 Salary SetID 0 Sal Plan 0 Grade 0 Step 0 Biweekly High Rate 0 Biweekly Low Rate 0 Union Code 0 Extended Step 0 Pay Type 0 dtype: int641salary_ranges.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Step Union Code Extended Step count 1356.000000 1356.000000 1356.000000 mean 1.294985 392.676991 0.150442 std 1.045816 338.100562 1.006734 min 1.000000 1.000000 0.000000 25% 1.000000 21.000000 0.000000 50% 1.000000 351.000000 0.000000 75% 1.000000 790.000000 0.000000 max 5.000000 990.000000 11.000000 1salary_ranges[['Biweekly High Rate','Grade']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Biweekly High Rate Grade 0 $0.00 00000 1 $15.00 00000 2 $25.00 00000 3 $50.00 00000 4 $100.00 00000 5 $100.00 00000 6 $200.00 00000 7 $500.00 00000 8 $0.00 00000 9 $10630.00 0140F 10 $9175.00 0150F 11 $4142.00 0170F 12 $5242.00 0180F 13 $3293.00 0190F 14 $4496.00 0380F 15 $4676.00 0381F 16 $4762.00 0382F 17 $11255.00 0390F 18 $10376.00 0395F 19 $9096.00 0400F 20 $9456.00 0401F 21 $9641.00 0402F 22 $7392.00 0488F 23 $7687.00 0489F 24 $7835.00 0490F 25 $3794.62 0720F 26 $1326.00 05475 27 $1425.00 05625 28 $1532.00 05775 29 $1646.00 05925 ... ... ... 1326 $4857.00 Q37H0 1327 $4586.00 Q50H0 1328 $4770.00 Q51H0 1329 $4857.00 Q52H0 1330 $5237.00 Q60H0 1331 $5445.00 Q61H0 1332 $5548.00 Q62H0 1333 $6616.00 Q80H0 1334 $6881.00 Q81H0 1335 $7011.00 Q82H0 1336 $6515.00 Q90H0 1337 $2178.00 06500 1338 $2342.00 06650 1339 $2700.00 06940 1340 $2354.00 06660 1341 $3234.00 07310 1342 $1909.00 06230 1343 $2332.00 06640 1344 $2459.00 06750 1345 $2354.00 06660 1346 $3199.00 07290 1347 $3426.00 07430 1348 $3689.00 07580 1349 $1951.00 06275 1350 $2786.00 07005 1351 $2145.00 06470 1352 $3041.00 07185 1353 $3132.00 07245 1354 $3453.00 07445 1355 $3453.00 07445 1356 rows × 2 columns 1salary_ranges['Biweekly High Rate'] = salary_ranges['Biweekly High Rate'].map(lambda x : x.replace('$','')) 1salary_ranges['Biweekly High Rate'] 0 0.00 1 15.00 2 25.00 3 50.00 4 100.00 5 100.00 6 200.00 7 500.00 8 0.00 9 10630.00 10 9175.00 11 4142.00 12 5242.00 13 3293.00 14 4496.00 15 4676.00 16 4762.00 17 11255.00 18 10376.00 19 9096.00 20 9456.00 21 9641.00 22 7392.00 23 7687.00 24 7835.00 25 3794.62 26 1326.00 27 1425.00 28 1532.00 29 1646.00 ... 1326 4857.00 1327 4586.00 1328 4770.00 1329 4857.00 1330 5237.00 1331 5445.00 1332 5548.00 1333 6616.00 1334 6881.00 1335 7011.00 1336 6515.00 1337 2178.00 1338 2342.00 1339 2700.00 1340 2354.00 1341 3234.00 1342 1909.00 1343 2332.00 1344 2459.00 1345 2354.00 1346 3199.00 1347 3426.00 1348 3689.00 1349 1951.00 1350 2786.00 1351 2145.00 1352 3041.00 1353 3132.00 1354 3453.00 1355 3453.00 Name: Biweekly High Rate, Length: 1356, dtype: object1salary_ranges['Biweekly High Rate'] = salary_ranges['Biweekly High Rate'].astype(float) 1salary_ranges['Grade'] = salary_ranges['Grade'].astype(str) 1salary_ranges.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } SetID Job Code Eff Date Sal End Date Salary SetID Sal Plan Grade Step Biweekly High Rate Biweekly Low Rate Union Code Extended Step Pay Type 0 COMMN 0109 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 0.0 $0.00 330 0 C 1 COMMN 0110 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 15.0 $15.00 323 0 D 2 COMMN 0111 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 25.0 $25.00 323 0 D 3 COMMN 0112 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 50.0 $50.00 323 0 D 4 COMMN 0114 07/01/2009 12:00:00 AM 06/30/2010 12:00:00 AM COMMN SFM 00000 1 100.0 $100.00 323 0 M 定类等级1salary_ranges['Grade'].value_counts().head() 00000 61 07450 12 06870 9 07420 9 07170 9 Name: Grade, dtype: int64 柱状图 1salary_ranges['Grade'].value_counts().sort_values(ascending = False).head(20).plot(kind = 'bar'); 1salary_ranges['Grade'].value_counts().sort_values(ascending = False).head(5).plot(kind = 'pie'); 定序等级1!cd E:\\Python\\特征工程入门与实践1customer = pd.read_csv('data/2013_SFO_Customer_survey.csv') 1customer.shape (3535, 95)12art_ratings = customer['Q7A_ART']art_ratings.describe() count 3535.000000 mean 4.300707 std 1.341445 min 0.000000 25% 3.000000 50% 4.000000 75% 5.000000 max 6.000000 Name: Q7A_ART, dtype: float641art_ratings = art_ratings[(art_ratings &gt; 1) &amp; (art_ratings &lt;= 5)] 12art_ratings = art_ratings.astype(str)art_ratings.describe() count 2636 unique 4 top 4 freq 1066 Name: Q7A_ART, dtype: object1art_ratings.value_counts().plot(kind = 'pie'); 1art_ratings.value_counts().plot(kind = 'bar'); 1art_ratings.value_counts().plot(kind = 'box'); 定序等级1climate = pd.read_csv('data/GlobalLandTemperaturesByCity.csv') 1climate.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dt AverageTemperature AverageTemperatureUncertainty City Country Latitude Longitude 0 1743-11-01 6.068 1.737 Århus Denmark 57.05N 10.33E 1 1743-12-01 NaN NaN Århus Denmark 57.05N 10.33E 2 1744-01-01 NaN NaN Århus Denmark 57.05N 10.33E 3 1744-02-01 NaN NaN Århus Denmark 57.05N 10.33E 4 1744-03-01 NaN NaN Århus Denmark 57.05N 10.33E 12# 移除缺失值climate.dropna(axis = 0, inplace = True) 1climate.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dt AverageTemperature AverageTemperatureUncertainty City Country Latitude Longitude 0 1743-11-01 6.068 1.737 Århus Denmark 57.05N 10.33E 5 1744-04-01 5.788 3.624 Århus Denmark 57.05N 10.33E 6 1744-05-01 10.644 1.283 Århus Denmark 57.05N 10.33E 7 1744-06-01 14.051 1.347 Århus Denmark 57.05N 10.33E 8 1744-07-01 16.082 1.396 Århus Denmark 57.05N 10.33E 1climate.isnull().sum() dt 0 AverageTemperature 0 AverageTemperatureUncertainty 0 City 0 Country 0 Latitude 0 Longitude 0 dtype: int641climate['AverageTemperature'].hist(); 1climate['AverageTemperature'].mean() 16.727432636247972123climate['dt'] = pd.to_datetime(climate['dt'])climate['year'] = climate['dt'].map(lambda x: x.year)climate_sub_us = climate.loc[climate['Country'] == 'United States'] 1climate_sub_us['century'] = climate_sub_us['year'].map(lambda x : int(x/100 + 1)) D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy &quot;&quot;&quot;Entry point for launching an IPython kernel.1climate_sub_us.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dt AverageTemperature AverageTemperatureUncertainty City Country Latitude Longitude year century 47555 1820-01-01 2.101 3.217 Abilene United States 32.95N 100.53W 1820 19 47556 1820-02-01 6.926 2.853 Abilene United States 32.95N 100.53W 1820 19 47557 1820-03-01 10.767 2.395 Abilene United States 32.95N 100.53W 1820 19 47558 1820-04-01 17.989 2.202 Abilene United States 32.95N 100.53W 1820 19 47559 1820-05-01 21.809 2.036 Abilene United States 32.95N 100.53W 1820 19 1climate_sub_us['AverageTemperature'].hist(by = climate_sub_us[\"century\"], sharex = True, sharey = True, figsize = (10,10), bins = 20); 1climate_sub_us.groupby('century')['AverageTemperature'].mean().plot(kind = 'line'); 12century_changes = climate_sub_us.groupby('century')['AverageTemperature'].mean()century_changes century 18 12.073243 19 13.662870 20 14.386622 21 15.197692 Name: AverageTemperature, dtype: float641century_changes[21] - century_changes[18] 3.12444911546075412345x = climate_sub_us['year']y = climate_sub_us['AverageTemperature']fig, ax = plt.subplots(figsize = (10,5))ax.scatter(x,y)plt.show() 1climate_sub_us.groupby('year').mean()['AverageTemperature'].plot(); 使用滑动均值平滑曲线 1climate_sub_us.groupby('year').mean()['AverageTemperature'].rolling(10).mean().plot(); 定比等级123456fig = plt.figure(figsize = (15,5))ax = fig.gca()salary_ranges.groupby('Grade')[['Biweekly High Rate']].mean().sort_values('Biweekly High Rate',ascending = False).head(20).plot.bar( stacked = False, ax= ax, color = 'darkorange');ax.set_title('Top 20 Grade by mean Biweekly High Rate'); 比较工资最高的员工与工资最低员工的差距 1sorted_df = salary_ranges.groupby('Grade')[['Biweekly High Rate']].mean().sort_values('Biweekly High Rate',ascending = False) 1sorted_df.iloc[0][0] / sorted_df.iloc[-1][0] 13.931919540229886","categories":[{"name":"feature project","slug":"feature-project","permalink":"http://yoursite.com/categories/feature-project/"}],"tags":[{"name":"特征工程入门与实践","slug":"特征工程入门与实践","permalink":"http://yoursite.com/tags/特征工程入门与实践/"}]},{"title":"Tips(2)","slug":"Tips (2)","date":"2019-07-12T12:37:55.075Z","updated":"2019-07-28T06:43:24.672Z","comments":true,"path":"2019/07/12/Tips (2)/","link":"","permalink":"http://yoursite.com/2019/07/12/Tips (2)/","excerpt":"","text":"Ubuntu 18.01 重装mysql 删除mysql 123 #sudo apt autoremove mysql-server #sudo apt remove mysql-common#dpkg -l |grep ^rc|awk &apos;&#123;print $2&#125;&apos; |sudo xargs dpkg -P 安装 mysql 123#sudo apt install mysql-server#sudo apt install mysql-client#sudo apt install php5-mysql php和mysql连接 若提示Package has no installation candidate 123sudo apt-get update sudo apt install upgradesudo apt install php5-mysql","categories":[],"tags":[]},{"title":"Google Colab使用2","slug":"Google colab Tips2","date":"2019-07-12T12:37:34.227Z","updated":"2019-08-09T03:20:35.835Z","comments":true,"path":"2019/07/12/Google colab Tips2/","link":"","permalink":"http://yoursite.com/2019/07/12/Google colab Tips2/","excerpt":"","text":"挂载Drive 12from google.colab import drive drive.mount(&apos;/content/drive&apos;) 接着打开链接输入授权码 虚拟机文件下载 12from google.colab import files files.download(&apos;file&quot;) # 同理，file.upload()","categories":[],"tags":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/tags/ML/"}]},{"title":"","slug":"naviat学习","date":"2019-07-12T12:37:15.179Z","updated":"2019-08-09T03:24:08.654Z","comments":true,"path":"2019/07/12/naviat学习/","link":"","permalink":"http://yoursite.com/2019/07/12/naviat学习/","excerpt":"","text":"title:Mysql学习记录2 tag:Mysql ERROR 1698 (28000): Access denied for user ‘root’@’localhost’转载自学习 进入以下文件1sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf 在如下位置，加入skip-grant-tables保存并退出。 重启mysqlservice mysql restart 重新进入mysql 1mysql -u root -p 123use mysql;update user set authentication_string=password(”你的密码“）where user=&quot;root&quot;;flush privileges; 再次进入mysql 12service mysql restartmysql -u root -p 如下修改 12use mysql;select user,plugin from user; 从图中可以看到在执行了select user,plugin from user后，错误原因是因为plugin root的字段是auth_socket，那我们改掉它为下面的mysql_native_password就行了。 12update user set authentication_string=password(&apos;你的密码&apos;),plugin=&apos;mysql_natice_password&apos; where user=&apos;root&apos;;select user,plugin from user; 此时有 最后注释掉之前的输入 1sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf 此时即可正常进入mysql 1mysql -u root -p","categories":[],"tags":[]},{"title":"Mysql学习记录","slug":"Mysql学习记录","date":"2019-07-12T12:37:04.427Z","updated":"2019-08-09T03:21:45.239Z","comments":true,"path":"2019/07/12/Mysql学习记录/","link":"","permalink":"http://yoursite.com/2019/07/12/Mysql学习记录/","excerpt":"mysql (内连接，外连接，左连接，右连接，自连接）学习记录 内连接只显示连接过程中交叉的部分 select * from A a inner join B b on a.id = b.id","text":"mysql (内连接，外连接，左连接，右连接，自连接）学习记录 内连接只显示连接过程中交叉的部分 select * from A a inner join B b on a.id = b.id 左连接右连接同属于外连接 select * from A a left join B b on a.id = b.id -- 显示左表全部记录以及左右表同时存在的记录 select * from A a right join B b on a.id = b.id -- 显示右表全部记录以及左右表同时存在的记录 为现有表添加主键 alter table my_contacts add column contact_id int not null auto_increment first, add primary key (contact_id); 使用CASE表达式来Updateupdate movie_tableset category =case when drama = &#39;T&#39; then &#39;drama&#39; when comedy = &#39;T&#39; then &#39;comedy&#39; else &#39;miscend;","categories":[],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://yoursite.com/tags/Mysql/"}]},{"title":"","slug":"Tips (1)","date":"2019-07-12T12:36:54.955Z","updated":"2019-07-12T12:36:55.683Z","comments":true,"path":"2019/07/12/Tips (1)/","link":"","permalink":"http://yoursite.com/2019/07/12/Tips (1)/","excerpt":"","text":"pymongo api 1234sheet_weather.update_one(&#123;&apos;_id&apos;: item[&apos;_id&apos;]&#125;, &#123;&apos;$set&apos;: &#123;&apos;HeWeather6.0.daily_forecast.&#123;&#125;.tmp_min&apos;.format(i): int(tmp)&#125;&#125;)sheet_weather.find_one_and_delete(&#123;&apos;_id&apos;:item[&apos;_id&apos;]&#125;,&#123;&apos;HeWeather6.0.daily_forecast.&#123;&#125;.tmp_min&apos;&#125;) {‘_id’: item[‘_id’]}表示需要更新的查询条件，对应_id字段。第二个参数表示要更新的信息，$set 为MongoDB的一个修改器，用于指定一个键并更新键值，若键不存在则创建一个键 常用的修改器还有： $inc 可以对文档的某个值为数字型的键进行增减操作 $unset 用于删除键 $push向文档的某个数组类型的键添加一个数组元素，不过滤重复的数据。添加时，若键存在，则要求键值类型必须为数组；若键不存在，则创建数组类型的键 {&#39;$set&#39;: {&#39;HeWeather6.0.daily_forecast.{}.tmp_min&#39;.format(i): int(tmp)}} url = &#39;https://free-api.heweather.net/s6/weather/forecast?location=&#39;+item[1:14]+&#39;&amp;key=aaaaaaaaaaaaa可以写成 1url = &apos;https://free-api.heweather.net/s6/weather/forecast?location=&#123;&#125;&amp;key=aaaa&apos;.format(item[1:14])","categories":[],"tags":[]},{"title":"","slug":"用API爬取天气预报数据","date":"2019-07-12T12:36:41.180Z","updated":"2019-07-12T15:21:31.508Z","comments":true,"path":"2019/07/12/用API爬取天气预报数据/","link":"","permalink":"http://yoursite.com/2019/07/12/用API爬取天气预报数据/","excerpt":"","text":"使用API爬去天气预报数据 Code123456789101112131415161718192021222324252627282930313233import requestsimport numpyimport reimport time# 加载pymongoimport pymongoclient = pymongo.MongoClient(&apos;localhost&apos;,27017)book_weather = client[&apos;weather&apos;]sheet_weather = book_weather[&apos;sheet_weather_3&apos;]url = &apos;https://cdn.heweather.com/china-city-list.txt&apos;strhtml = requests.get(url)strhtml.encoding = &apos;utf-8&apos;data = strhtml.textdata1 = data.split(&apos;\\n&apos;)for i in range(6): data1.remove(data1[0])for item in data1: # url = &apos;https://free-api.weather.com/v5/forecast?city=&apos;+ item[0:11] +&apos;&amp;key=yourownkey&apos; url = &apos;https://free-api.heweather.net/s6/weather/forecast?location=&#123;&#125;&amp;key=yourownkey&apos;.format(item[1:14]) strhtml = requests.get(url) # print(strhtml) time.sleep(1) dic = strhtml.json() # 向表写入一条数据 sheet_weather.insert_one(dic)import pymongoclient = pymongo.MongoClient(&apos;localhost&apos;,27017)book_weather = client[&apos;weather&apos;]sheet_weather = book_weather[&apos;sheet_weather_3&apos;] 查询未来三天最低气温低于5度的地点 123456789101112131415import pymongoclient = pymongo.MongoClient(&apos;localhost&apos;,27017)book_weather = client[&apos;weather&apos;]sheet_weather = book_weather[&apos;sheet_weather_3&apos;]for item in sheet_weather.find(): for i in range(3): tmp = item[&apos;HeWeather6&apos;][0][&apos;daily_forecast&apos;][i][&apos;tmp_min&apos;] sheet_weather.update_one(&#123;&apos;_id&apos;: item[&apos;_id&apos;]&#125;, &#123;&apos;$set&apos;: &#123;&apos;HeWeather6.0.daily_forecast.&#123;&#125;.tmp_min&apos;.format(i): int(tmp)&#125;&#125;) #sheet_weather.find_one_and_delete(&#123;&apos;_id&apos;:item[&apos;_id&apos;]&#125;,&#123;&apos;HeWeather6.0.daily_forecast.&#123;&#125;.tmp_min&apos;&#125;)for item in sheet_weather.find(&#123;&apos;HeWeather6.0.daily_forecast.tmp_min&apos;:&#123;&apos;$gt&apos;:5&#125;&#125;): print(item[&apos;HeWeather6&apos;][0][&apos;basic&apos;][&apos;location&apos;]) $lt, $lte, $gt, $gte 分别表示&lt; , &lt;=, &gt;, &gt;=","categories":[],"tags":[]},{"title":"","slug":"Tips","date":"2019-07-12T12:36:31.572Z","updated":"2019-07-12T12:36:32.295Z","comments":true,"path":"2019/07/12/Tips/","link":"","permalink":"http://yoursite.com/2019/07/12/Tips/","excerpt":"","text":"以癌症预测为例 0:恶性，1:良性 TP： 真正例，良性被正确预测 TN：真反例，恶性被正确预测 FP：假正例，恶性被预测为良性 FN：假反例，良性被预测为恶性 Accuracy:准确率（TP+TN）/（TP+TN+FP+FN）Precision:查准率 TP/(TP+FP)Recall:查全率 TP/(TP+FN) 12345678import numpy as np arr = np.arange(12).reshape(3,4)print(arr)a = arr[:,::2]print(a)b = arr[::1,:]print(b) 123456789[[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]][[ 0 2] [ 4 6] [ 8 10]][[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]]","categories":[],"tags":[]},{"title":"","slug":"T","date":"2019-07-12T12:36:10.659Z","updated":"2019-07-12T12:36:13.088Z","comments":true,"path":"2019/07/12/T/","link":"","permalink":"http://yoursite.com/2019/07/12/T/","excerpt":"","text":"operator.itemgetter operator 12sorted = sorted(data,key = operator.itemgetter(n))---operator.itemgetter(n)返回位置n上的元素 zip `np.c_ np.r_ np.meshgrid` x = np.arange(1,3,1) y = np.arange(4,8,1) xx,yy = np.meshgrid(x,y) print(xx,yy ) print(xx.ravel()) print(yy.ravel()) 1234567891011121314151617x = np.linespace(1,10,10)y = np.linespace(2,8,6)x1,x2 = np.meshgrid(x,y) #返回list,有两个元素,第一个元素是X轴的取值,第二个元素是Y轴的取值》》》[[ 1. 2. 3. 4. 5. 6. 7. 8. 9. 10.] [ 1. 2. 3. 4. 5. 6. 7. 8. 9. 10.] [ 1. 2. 3. 4. 5. 6. 7. 8. 9. 10.] [ 1. 2. 3. 4. 5. 6. 7. 8. 9. 10.] [ 1. 2. 3. 4. 5. 6. 7. 8. 9. 10.] [ 1. 2. 3. 4. 5. 6. 7. 8. 9. 10.] [ 1. 2. 3. 4. 5. 6. 7. 8. 9. 10.]] [[2. 2. 2. 2. 2. 2. 2. 2. 2. 2.] [3. 3. 3. 3. 3. 3. 3. 3. 3. 3.] [4. 4. 4. 4. 4. 4. 4. 4. 4. 4.] [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.] [6. 6. 6. 6. 6. 6. 6. 6. 6. 6.] [7. 7. 7. 7. 7. 7. 7. 7. 7. 7.] [8. 8. 8. 8. 8. 8. 8. 8. 8. 8.]] pandas 计算偏度和峰度1234567891011121314%matplotlib inlineimport pandas as pdfrom sklearn.datasets import load_iris import matplotlib.pyplot as pltimport seaborn as snsiris = load_iris()x = iris.datay = iris.targetxx.columnsprint(&quot;鸢尾花长度的偏度：%f&quot; % xx[&apos;sepal length (cm)&apos;].skew())print(&quot;鸢尾花长度的峰度：%f&quot; % xx[&apos;sepal length (cm)&apos;].kurt())","categories":[],"tags":[]},{"title":"MNIST数据集的读取","slug":"MNIST数据集的读取","date":"2019-07-12T03:38:04.442Z","updated":"2019-08-09T03:25:14.716Z","comments":true,"path":"2019/07/12/MNIST数据集的读取/","link":"","permalink":"http://yoursite.com/2019/07/12/MNIST数据集的读取/","excerpt":"下载MNIST 数据集，并保存到home/wang/文档/Linux_python/ML/Python_ml test/MNIST_data/mldata文件夹下","text":"下载MNIST 数据集，并保存到home/wang/文档/Linux_python/ML/Python_ml test/MNIST_data/mldata文件夹下 123456789101112from sklearn.datasets import fetch_mldatamnist = fetch_mldata(&apos;mnist-original&apos;, data_home = &apos;/home/wang/文档/Linux_python/ML/Python_ml test/MNIST_data&apos;)X = mnist[&apos;data&apos;]y = mnist[&apos;target&apos;]print(X)print(y)from sklearn.model_selection import train_test_splitX_train,X_test,y_train,y_test = train_test_split(X,y)","categories":[{"name":"Machine Learning","slug":"Machine-Learning","permalink":"http://yoursite.com/categories/Machine-Learning/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://yoursite.com/tags/ML/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-07-12T02:06:54.964Z","updated":"2019-07-12T02:06:54.964Z","comments":true,"path":"2019/07/12/hello-world/","link":"","permalink":"http://yoursite.com/2019/07/12/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}